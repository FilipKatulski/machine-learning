{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab5\n",
    "\n",
    "Filip Katulski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussowski Naiwny Klasyfikator Bayesa\n",
    "\n",
    "### Zadania 1, 2:\n",
    "\n",
    "Klasa NaiveBayesClassifier zawiera metody słuzące do wyliczenia Naiwnego Bayesa dla zadanego zbioru danych.\n",
    "\n",
    "Metody mean, probability, stddev, fit są wyliczane dla kazdej z zadanych klas (target). \n",
    "\n",
    "Dla obliczeć prawdpodobieństwa a posteriori uzyłem formuły wyprowadzonej jako suma logarytmów, wyprowadzenie [tutaj](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    # Train, Test jako Pandas Dataframe, mozliwosc uzywania funkcji groupby, apply, to_numpy.\n",
    "\n",
    "    def calculate_means(self, train, target):\n",
    "        self.means = train.groupby(target).apply(np.mean).to_numpy()\n",
    "\n",
    "    def calculate_variances(self, train, target):\n",
    "        self.vars = train.groupby(target).apply(np.var).to_numpy()\n",
    "\n",
    "    def calculate_priors(self, train, target):\n",
    "        # shape[0] zwraca ilosc elementow dla danego targetu \n",
    "        self.priors = (train.groupby(target).apply(lambda x: len(x))/train.shape[0]).to_numpy()\n",
    "  \n",
    "    # Zgodnie ze wzorem Eq. 5 \n",
    "    def gaussian(self, x, mean, variance):\n",
    "        return np.exp((-1/2)*((x - mean[:-1])**2) / (2 * variance[:-1])) / np.sqrt(2 * np.pi * variance[:-1])\n",
    "\n",
    "    def posterior_probability(self, x):\n",
    "        posteriors = []\n",
    "        for i in range(len(self.classes)):\n",
    "            prior = np.log(self.priors[i])\n",
    "            # iloczyn jako suma logarytmow, link do wyprowadzenia powyzej \n",
    "            sub_sum_logs = np.sum(np.log(self.gaussian(x, self.means[i], self.vars[i])))\n",
    "            posterior = prior + sub_sum_logs\n",
    "\n",
    "            posteriors.append(posterior)\n",
    "        \n",
    "            # maksymalna wartość praw. a posteriori\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "    def fit(self, train, target):\n",
    "        self.calculate_means(train, target)\n",
    "        self.calculate_variances(train, target)\n",
    "        self.calculate_priors(train, target)\n",
    "        self.classes = np.unique(train[target])\n",
    "\n",
    "    # założenie dla podzbiorów \"test\" - ostatnia kolumna to \"target\"\n",
    "    def predict(self, test):\n",
    "        return [self.posterior_probability(x) for x in test.to_numpy()]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3\n",
    "\n",
    "Test implementacji dla zbioru Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted, actual):\n",
    "  return np.sum(predicted == actual) / len(predicted)\n",
    "\n",
    "def error(predicted, actual):\n",
    "  return 1.0 - accuracy(predicted, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Iteration: 0 \n",
      " error: 0.01666666666666672\n",
      "|Iteration: 1 \n",
      " error: 0.01666666666666672\n",
      "|Iteration: 2 \n",
      " error: 0.050000000000000044\n",
      "|Iteration: 3 \n",
      " error: 0.050000000000000044\n",
      "|Iteration: 4 \n",
      " error: 0.050000000000000044\n",
      "|Iteration: 5 \n",
      " error: 0.050000000000000044\n",
      "|Iteration: 6 \n",
      " error: 0.033333333333333326\n",
      "|Iteration: 7 \n",
      " error: 0.01666666666666672\n",
      "|Iteration: 8 \n",
      " error: 0.050000000000000044\n",
      "|Iteration: 9 \n",
      " error: 0.08333333333333337\n",
      "|Iteration: 10 \n",
      " error: 0.033333333333333326\n",
      "|Iteration: 11 \n",
      " error: 0.06666666666666665\n",
      "|Iteration: 12 \n",
      " error: 0.050000000000000044\n",
      "|Iteration: 13 \n",
      " error: 0.050000000000000044\n",
      "|Iteration: 14 \n",
      " error: 0.050000000000000044\n",
      "|Iteration: 15 \n",
      " error: 0.08333333333333337\n",
      "|Iteration: 16 \n",
      " error: 0.050000000000000044\n",
      "|Iteration: 17 \n",
      " error: 0.06666666666666665\n",
      "|Iteration: 18 \n",
      " error: 0.050000000000000044\n",
      "|Iteration: 19 \n",
      " error: 0.033333333333333326\n",
      "Mean error: 0.04750000000000003\n",
      "Error variance: 0.000340972222222222\n"
     ]
    }
   ],
   "source": [
    "# Numpy zwraca ostrzezenia odnosnie nowej wersji niektorych funkcji, \n",
    "# zostały one wyciszone. \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "iris_df= load_iris(as_frame=True)\n",
    "errors = []\n",
    "for iteration in range(20):\n",
    "    train, test = train_test_split(iris_df['frame'], test_size=0.4)\n",
    "    X_test, y_test = test.drop(columns=['target']), test['target']\n",
    "    cls = NaiveBayesClassifier()\n",
    "    cls.fit(train, 'target')\n",
    "    predictions = cls.predict(X_test)\n",
    "    errors.append(error(predictions, y_test))\n",
    "    print(\"|Iteration: {0} \\n error: {1}\".format(iteration, errors[iteration]))\n",
    "\n",
    "print(\"Mean error:\", np.mean(errors))\n",
    "print(\"Error variance:\", np.var(errors))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4\n",
    "\n",
    "Zbiór Wine. StandardScaler do standaryzacji danych wejściowych, PCA do redukcji wymiarowości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f4e115e75834b3640c3ba940ce468eb8c4fe6d47c62ca06ee89b297ba5a8d03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
